2024-08-05 13:36:48 INFO  StreamsConfig:372 - StreamsConfig values: 
	acceptable.recovery.lag = 10000
	application.id = word-count
	application.server = 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:29092]
	buffered.records.per.partition = 1000
	built.in.metrics.version = latest
	cache.max.bytes.buffering = 10485760
	client.id = 
	commit.interval.ms = 30000
	connections.max.idle.ms = 540000
	default.client.supplier = class org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier
	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
	default.dsl.store = rocksDB
	default.key.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
	default.list.key.serde.inner = null
	default.list.key.serde.type = null
	default.list.value.serde.inner = null
	default.list.value.serde.type = null
	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
	default.value.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
	dsl.store.suppliers.class = class org.apache.kafka.streams.state.BuiltInDslStoreSuppliers$RocksDBDslStoreSuppliers
	enable.metrics.push = true
	max.task.idle.ms = 0
	max.warmup.replicas = 2
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	num.standby.replicas = 0
	num.stream.threads = 1
	poll.ms = 100
	probing.rebalance.interval.ms = 600000
	processing.guarantee = at_least_once
	rack.aware.assignment.non_overlap_cost = null
	rack.aware.assignment.strategy = none
	rack.aware.assignment.tags = []
	rack.aware.assignment.traffic_cost = null
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	repartition.purge.interval.ms = 30000
	replication.factor = -1
	request.timeout.ms = 40000
	retries = 0
	retry.backoff.ms = 100
	rocksdb.config.setter = null
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	state.cleanup.delay.ms = 600000
	state.dir = C:\one-place\practice\kafka-streams
	statestore.cache.max.bytes = 10485760
	task.assignor.class = null
	task.timeout.ms = 300000
	topology.optimization = none
	upgrade.from = null
	window.size.ms = null
	windowed.inner.class.serde = null
	windowstore.changelog.additional.retention.ms = 86400000

2024-08-05 13:36:48 ERROR StateDirectory:163 - Failed to change permissions for the directory C:\one-place\practice\kafka-streams
2024-08-05 13:36:48 ERROR StateDirectory:163 - Failed to change permissions for the directory C:\one-place\practice\kafka-streams\word-count
2024-08-05 13:36:49 INFO  StateDirectory:205 - Reading UUID from process file: b83c725f-2c5a-4176-a382-e67c3dee9b4a
2024-08-05 13:36:49 INFO  AdminClientConfig:372 - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [localhost:29092]
	client.dns.lookup = use_all_dns_ips
	client.id = word-count-b83c725f-2c5a-4176-a382-e67c3dee9b4a-admin
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2024-08-05 13:36:49 INFO  AppInfoParser:124 - Kafka version: 3.8.0
2024-08-05 13:36:49 INFO  AppInfoParser:125 - Kafka commitId: 771b9576b00ecf5b
2024-08-05 13:36:49 INFO  AppInfoParser:126 - Kafka startTimeMs: 1722845209470
2024-08-05 13:36:49 INFO  KafkaStreams:998 - stream-client [word-count-b83c725f-2c5a-4176-a382-e67c3dee9b4a] Kafka Streams version: 3.8.0
2024-08-05 13:36:49 INFO  KafkaStreams:999 - stream-client [word-count-b83c725f-2c5a-4176-a382-e67c3dee9b4a] Kafka Streams commit ID: 771b9576b00ecf5b
2024-08-05 13:36:49 INFO  StreamThread:383 - stream-thread [word-count-b83c725f-2c5a-4176-a382-e67c3dee9b4a-StreamThread-1] Creating restore consumer client
2024-08-05 13:36:49 INFO  ConsumerConfig:372 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = none
	bootstrap.servers = [localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = word-count-b83c725f-2c5a-4176-a382-e67c3dee9b4a-StreamThread-1-restore-consumer
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = null
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2024-08-05 13:36:49 INFO  KafkaMetricsCollector:269 - initializing Kafka metrics collector
2024-08-05 13:36:49 INFO  AppInfoParser:124 - Kafka version: 3.8.0
2024-08-05 13:36:49 INFO  AppInfoParser:125 - Kafka commitId: 771b9576b00ecf5b
2024-08-05 13:36:49 INFO  AppInfoParser:126 - Kafka startTimeMs: 1722845209592
2024-08-05 13:36:49 INFO  StreamThread:104 - stream-thread [word-count-b83c725f-2c5a-4176-a382-e67c3dee9b4a-StreamThread-1] Creating thread producer client
2024-08-05 13:36:49 INFO  ProducerConfig:372 - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:29092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = word-count-b83c725f-2c5a-4176-a382-e67c3dee9b4a-StreamThread-1-producer
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 100
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2024-08-05 13:36:49 INFO  KafkaMetricsCollector:269 - initializing Kafka metrics collector
2024-08-05 13:36:49 INFO  KafkaProducer:621 - [Producer clientId=word-count-b83c725f-2c5a-4176-a382-e67c3dee9b4a-StreamThread-1-producer] Instantiated an idempotent producer.
2024-08-05 13:36:49 INFO  AppInfoParser:124 - Kafka version: 3.8.0
2024-08-05 13:36:49 INFO  AppInfoParser:125 - Kafka commitId: 771b9576b00ecf5b
2024-08-05 13:36:49 INFO  AppInfoParser:126 - Kafka startTimeMs: 1722845209666
2024-08-05 13:36:49 INFO  DefaultStateUpdater:144 - state-updater [word-count-b83c725f-2c5a-4176-a382-e67c3dee9b4a-StateUpdater-1] State updater thread started
2024-08-05 13:36:49 INFO  StreamThread:461 - stream-thread [word-count-b83c725f-2c5a-4176-a382-e67c3dee9b4a-StreamThread-1] Creating consumer client
2024-08-05 13:36:49 INFO  ConsumerConfig:372 - ConsumerConfig values: 
	allow.auto.create.topics = false
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = word-count-b83c725f-2c5a-4176-a382-e67c3dee9b4a-StreamThread-1-consumer
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = word-count
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = false
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2024-08-05 13:36:49 INFO  KafkaMetricsCollector:269 - initializing Kafka metrics collector
2024-08-05 13:36:49 INFO  AssignorConfiguration:144 - stream-thread [word-count-b83c725f-2c5a-4176-a382-e67c3dee9b4a-StreamThread-1-consumer] Cooperative rebalancing protocol is enabled now
2024-08-05 13:36:49 INFO  ConsumerConfig:381 - These configurations '[replication.factor, probing.rebalance.interval.ms, max.warmup.replicas, acceptable.recovery.lag, task.assignor.class, rack.aware.assignment.non_overlap_cost, application.server, rack.aware.assignment.strategy, rack.aware.assignment.traffic_cost, windowstore.changelog.additional.retention.ms, num.standby.replicas, upgrade.from, rack.aware.assignment.tags, application.id]' were supplied but are not used yet.
2024-08-05 13:36:49 INFO  AppInfoParser:124 - Kafka version: 3.8.0
2024-08-05 13:36:49 INFO  AppInfoParser:125 - Kafka commitId: 771b9576b00ecf5b
2024-08-05 13:36:49 INFO  AppInfoParser:126 - Kafka startTimeMs: 1722845209752
2024-08-05 13:36:49 INFO  KafkaStreams:346 - stream-client [word-count-b83c725f-2c5a-4176-a382-e67c3dee9b4a] State transition from CREATED to REBALANCING
2024-08-05 13:36:49 INFO  KafkaStreams:1411 - stream-client [word-count-b83c725f-2c5a-4176-a382-e67c3dee9b4a] Started 1 stream threads
2024-08-05 13:36:49 INFO  StreamThread:663 - stream-thread [word-count-b83c725f-2c5a-4176-a382-e67c3dee9b4a-StreamThread-1] Starting
2024-08-05 13:36:49 INFO  StreamThread:250 - stream-thread [word-count-b83c725f-2c5a-4176-a382-e67c3dee9b4a-StreamThread-1] State transition from CREATED to STARTING
2024-08-05 13:36:49 INFO  LegacyKafkaConsumer:476 - [Consumer clientId=word-count-b83c725f-2c5a-4176-a382-e67c3dee9b4a-StreamThread-1-consumer, groupId=word-count] Subscribed to topic(s): word-count-KSTREAM-AGGREGATE-STATE-STORE-0000000004-repartition, word-count-input
2024-08-05 13:36:49 INFO  Metadata:364 - [Producer clientId=word-count-b83c725f-2c5a-4176-a382-e67c3dee9b4a-StreamThread-1-producer] Cluster ID: vRkvCpUxRSSK1J8zZ2wP5w
2024-08-05 13:36:49 INFO  TransactionManager:502 - [Producer clientId=word-count-b83c725f-2c5a-4176-a382-e67c3dee9b4a-StreamThread-1-producer] ProducerId set to 6 with epoch 0
2024-08-05 13:36:49 INFO  Metadata:364 - [Consumer clientId=word-count-b83c725f-2c5a-4176-a382-e67c3dee9b4a-StreamThread-1-consumer, groupId=word-count] Cluster ID: vRkvCpUxRSSK1J8zZ2wP5w
2024-08-05 13:36:49 INFO  ConsumerCoordinator:936 - [Consumer clientId=word-count-b83c725f-2c5a-4176-a382-e67c3dee9b4a-StreamThread-1-consumer, groupId=word-count] Discovered group coordinator localhost:29092 (id: 2147483646 rack: null)
2024-08-05 13:36:49 INFO  StreamThread:1074 - stream-thread [word-count-b83c725f-2c5a-4176-a382-e67c3dee9b4a-StreamThread-1] Processed 0 total records, ran 0 punctuators, and committed 0 total tasks since the last update
2024-08-05 13:36:49 INFO  ConsumerCoordinator:604 - [Consumer clientId=word-count-b83c725f-2c5a-4176-a382-e67c3dee9b4a-StreamThread-1-consumer, groupId=word-count] (Re-)joining group
2024-08-05 13:36:49 INFO  ConsumerCoordinator:1102 - [Consumer clientId=word-count-b83c725f-2c5a-4176-a382-e67c3dee9b4a-StreamThread-1-consumer, groupId=word-count] Request joining group due to: need to re-join with the given member-id: word-count-b83c725f-2c5a-4176-a382-e67c3dee9b4a-StreamThread-1-consumer-36e4a022-8c40-404d-8e8f-8fcfafb4af62
2024-08-05 13:36:49 INFO  ConsumerCoordinator:604 - [Consumer clientId=word-count-b83c725f-2c5a-4176-a382-e67c3dee9b4a-StreamThread-1-consumer, groupId=word-count] (Re-)joining group
2024-08-05 13:36:52 INFO  ConsumerCoordinator:665 - [Consumer clientId=word-count-b83c725f-2c5a-4176-a382-e67c3dee9b4a-StreamThread-1-consumer, groupId=word-count] Successfully joined group with generation Generation{generationId=8, memberId='word-count-b83c725f-2c5a-4176-a382-e67c3dee9b4a-StreamThread-1-consumer-36e4a022-8c40-404d-8e8f-8fcfafb4af62', protocol='stream'}
2024-08-05 13:36:52 WARN  KafkaAdminClient:2293 - [AdminClient clientId=word-count-b83c725f-2c5a-4176-a382-e67c3dee9b4a-admin] The DescribeTopicPartitions API is not supported, using Metadata API to describe topics.
2024-08-05 13:36:52 WARN  KafkaAdminClient:2293 - [AdminClient clientId=word-count-b83c725f-2c5a-4176-a382-e67c3dee9b4a-admin] The DescribeTopicPartitions API is not supported, using Metadata API to describe topics.
2024-08-05 13:36:53 INFO  StreamsPartitionAssignor:778 - stream-thread [word-count-b83c725f-2c5a-4176-a382-e67c3dee9b4a-StreamThread-1-consumer] 1 client nodes and 1 consumers participating in this rebalance: 
b83c725f-2c5a-4176-a382-e67c3dee9b4a: [word-count-b83c725f-2c5a-4176-a382-e67c3dee9b4a-StreamThread-1-consumer-36e4a022-8c40-404d-8e8f-8fcfafb4af62].
2024-08-05 13:36:53 INFO  StreamsPartitionAssignor:789 - stream-thread [word-count-b83c725f-2c5a-4176-a382-e67c3dee9b4a-StreamThread-1-consumer] Assigning stateful tasks: [1_0]
and stateless tasks: [0_0]
2024-08-05 13:36:53 INFO  AssignorConfiguration:259 - stream-thread [word-count-b83c725f-2c5a-4176-a382-e67c3dee9b4a-StreamThread-1-consumer] No custom task assignors found, defaulting to internal task assignment with internal.task.assignor.class
2024-08-05 13:36:53 INFO  HighAvailabilityTaskAssignor:107 - Decided on assignment: {b83c725f-2c5a-4176-a382-e67c3dee9b4a=[activeTasks: ([0_0, 1_0]) standbyTasks: ([]) prevActiveTasks: ([]) prevStandbyTasks: ([1_0]) changelogOffsetTotalsByTask: ([1_0=6]) taskLagTotals: ([1_0=3]) clientTags: ([]) capacity: 1 assigned: 2]} with no followup probing rebalance.
2024-08-05 13:36:53 INFO  StreamsPartitionAssignor:850 - stream-thread [word-count-b83c725f-2c5a-4176-a382-e67c3dee9b4a-StreamThread-1-consumer] Assigned 2 total tasks including 1 stateful tasks to 1 client nodes.
2024-08-05 13:36:53 INFO  StreamsPartitionAssignor:854 - stream-thread [word-count-b83c725f-2c5a-4176-a382-e67c3dee9b4a-StreamThread-1-consumer] Assignment of tasks to nodes: b83c725f-2c5a-4176-a382-e67c3dee9b4a=[activeTasks: ([0_0, 1_0]) standbyTasks: ([])]
2024-08-05 13:36:53 INFO  StreamsPartitionAssignor:1081 - stream-thread [word-count-b83c725f-2c5a-4176-a382-e67c3dee9b4a-StreamThread-1-consumer] Client b83c725f-2c5a-4176-a382-e67c3dee9b4a per-consumer assignment:
	prev owned active {}
	prev owned standby {word-count-b83c725f-2c5a-4176-a382-e67c3dee9b4a-StreamThread-1-consumer-36e4a022-8c40-404d-8e8f-8fcfafb4af62=[1_0]}
	assigned active {word-count-b83c725f-2c5a-4176-a382-e67c3dee9b4a-StreamThread-1-consumer-36e4a022-8c40-404d-8e8f-8fcfafb4af62=[1_0, 0_0]}
	revoking active {}
	assigned standby {}

2024-08-05 13:36:53 INFO  StreamsPartitionAssignor:1100 - stream-thread [word-count-b83c725f-2c5a-4176-a382-e67c3dee9b4a-StreamThread-1-consumer] Finished stable assignment of tasks, no followup rebalances required.
2024-08-05 13:36:53 INFO  ConsumerCoordinator:663 - [Consumer clientId=word-count-b83c725f-2c5a-4176-a382-e67c3dee9b4a-StreamThread-1-consumer, groupId=word-count] Finished assignment for group at generation 8: {word-count-b83c725f-2c5a-4176-a382-e67c3dee9b4a-StreamThread-1-consumer-36e4a022-8c40-404d-8e8f-8fcfafb4af62=Assignment(partitions=[word-count-KSTREAM-AGGREGATE-STATE-STORE-0000000004-repartition-0, word-count-input-0], userDataSize=64)}
2024-08-05 13:36:53 INFO  ConsumerCoordinator:842 - [Consumer clientId=word-count-b83c725f-2c5a-4176-a382-e67c3dee9b4a-StreamThread-1-consumer, groupId=word-count] Successfully synced group in generation Generation{generationId=8, memberId='word-count-b83c725f-2c5a-4176-a382-e67c3dee9b4a-StreamThread-1-consumer-36e4a022-8c40-404d-8e8f-8fcfafb4af62', protocol='stream'}
2024-08-05 13:36:53 INFO  ConsumerCoordinator:386 - [Consumer clientId=word-count-b83c725f-2c5a-4176-a382-e67c3dee9b4a-StreamThread-1-consumer, groupId=word-count] Updating assignment with
	Assigned partitions:                       [word-count-KSTREAM-AGGREGATE-STATE-STORE-0000000004-repartition-0, word-count-input-0]
	Current owned partitions:                  []
	Added partitions (assigned - owned):       [word-count-KSTREAM-AGGREGATE-STATE-STORE-0000000004-repartition-0, word-count-input-0]
	Revoked partitions (owned - assigned):     []

2024-08-05 13:36:53 INFO  ConsumerCoordinator:323 - [Consumer clientId=word-count-b83c725f-2c5a-4176-a382-e67c3dee9b4a-StreamThread-1-consumer, groupId=word-count] Notifying assignor about the new Assignment(partitions=[word-count-KSTREAM-AGGREGATE-STATE-STORE-0000000004-repartition-0, word-count-input-0], userDataSize=64)
2024-08-05 13:36:53 INFO  StreamsPartitionAssignor:1581 - stream-thread [word-count-b83c725f-2c5a-4176-a382-e67c3dee9b4a-StreamThread-1-consumer] No followup rebalance was requested, resetting the rebalance schedule.
2024-08-05 13:36:53 INFO  TaskManager:335 - stream-thread [word-count-b83c725f-2c5a-4176-a382-e67c3dee9b4a-StreamThread-1] Handle new assignment with:
	New active tasks: [1_0, 0_0]
	New standby tasks: []
	Existing active tasks: []
	Existing standby tasks: []
2024-08-05 13:36:53 INFO  ConsumerRebalanceListenerInvoker:57 - [Consumer clientId=word-count-b83c725f-2c5a-4176-a382-e67c3dee9b4a-StreamThread-1-consumer, groupId=word-count] Adding newly assigned partitions: word-count-KSTREAM-AGGREGATE-STATE-STORE-0000000004-repartition-0, word-count-input-0
2024-08-05 13:36:53 INFO  StreamThread:250 - stream-thread [word-count-b83c725f-2c5a-4176-a382-e67c3dee9b4a-StreamThread-1] State transition from STARTING to PARTITIONS_ASSIGNED
2024-08-05 13:36:53 INFO  ConsumerUtils:201 - Setting offset for partition word-count-input-0 to the committed offset FetchPosition{offset=3, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 1 rack: null)], epoch=0}}
2024-08-05 13:36:53 INFO  ConsumerUtils:201 - Setting offset for partition word-count-KSTREAM-AGGREGATE-STATE-STORE-0000000004-repartition-0 to the committed offset FetchPosition{offset=12, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 1 rack: null)], epoch=0}}
2024-08-05 13:36:53 INFO  StreamTask:267 - stream-thread [word-count-b83c725f-2c5a-4176-a382-e67c3dee9b4a-StreamThread-1] task [0_0] Initialized
2024-08-05 13:36:53 INFO  DefaultStateUpdater:488 - state-updater [word-count-b83c725f-2c5a-4176-a382-e67c3dee9b4a-StateUpdater-1] Stateless active task 0_0 was added to the restored tasks of the state updater
2024-08-05 13:36:53 INFO  RocksDBTimestampedStore:83 - Opening store KSTREAM-AGGREGATE-STATE-STORE-0000000004 in regular mode
2024-08-05 13:36:53 INFO  ProcessorStateManager:273 - stream-thread [word-count-b83c725f-2c5a-4176-a382-e67c3dee9b4a-StreamThread-1] stream-task [1_0] State store KSTREAM-AGGREGATE-STATE-STORE-0000000004 initialized from checkpoint with offset 6 at changelog word-count-KSTREAM-AGGREGATE-STATE-STORE-0000000004-changelog-0
2024-08-05 13:36:53 INFO  StreamTask:267 - stream-thread [word-count-b83c725f-2c5a-4176-a382-e67c3dee9b4a-StreamThread-1] task [1_0] Initialized
2024-08-05 13:36:53 INFO  DefaultStateUpdater:498 - state-updater [word-count-b83c725f-2c5a-4176-a382-e67c3dee9b4a-StateUpdater-1] Stateful active task 1_0 was added to the state updater
2024-08-05 13:36:53 INFO  StoreChangelogReader:871 - stream-thread [word-count-b83c725f-2c5a-4176-a382-e67c3dee9b4a-StreamThread-1] End offset for changelog word-count-KSTREAM-AGGREGATE-STATE-STORE-0000000004-changelog-0 initialized as 9.
2024-08-05 13:36:53 INFO  StreamTask:295 - stream-thread [word-count-b83c725f-2c5a-4176-a382-e67c3dee9b4a-StreamThread-1] task [0_0] Restored and ready to run
2024-08-05 13:36:53 INFO  LegacyKafkaConsumer:574 - [Consumer clientId=word-count-b83c725f-2c5a-4176-a382-e67c3dee9b4a-StreamThread-1-restore-consumer, groupId=null] Assigned to partition(s): word-count-KSTREAM-AGGREGATE-STATE-STORE-0000000004-changelog-0
2024-08-05 13:36:53 INFO  LegacyKafkaConsumer:759 - [Consumer clientId=word-count-b83c725f-2c5a-4176-a382-e67c3dee9b4a-StreamThread-1-restore-consumer, groupId=null] Seeking to offset 7 for partition word-count-KSTREAM-AGGREGATE-STATE-STORE-0000000004-changelog-0
2024-08-05 13:36:53 INFO  Metadata:364 - [Consumer clientId=word-count-b83c725f-2c5a-4176-a382-e67c3dee9b4a-StreamThread-1-restore-consumer, groupId=null] Cluster ID: vRkvCpUxRSSK1J8zZ2wP5w
2024-08-05 13:36:53 INFO  StoreChangelogReader:692 - stream-thread [word-count-b83c725f-2c5a-4176-a382-e67c3dee9b4a-StreamThread-1] Finished restoring changelog word-count-KSTREAM-AGGREGATE-STATE-STORE-0000000004-changelog-0 to store KSTREAM-AGGREGATE-STATE-STORE-0000000004 with a total number of 2 records
2024-08-05 13:36:53 INFO  LegacyKafkaConsumer:547 - [Consumer clientId=word-count-b83c725f-2c5a-4176-a382-e67c3dee9b4a-StreamThread-1-restore-consumer, groupId=null] Unsubscribed all topics or patterns and assigned partitions
2024-08-05 13:36:53 INFO  DefaultStateUpdater:678 - state-updater [word-count-b83c725f-2c5a-4176-a382-e67c3dee9b4a-StateUpdater-1] Stateful active task 1_0 completed restoration
2024-08-05 13:36:53 INFO  LegacyKafkaConsumer:1047 - [Consumer clientId=word-count-b83c725f-2c5a-4176-a382-e67c3dee9b4a-StreamThread-1-consumer, groupId=word-count] Requesting the log end offset for word-count-input-0 in order to compute lag
2024-08-05 13:36:53 INFO  StreamTask:295 - stream-thread [word-count-b83c725f-2c5a-4176-a382-e67c3dee9b4a-StreamThread-1] task [1_0] Restored and ready to run
2024-08-05 13:36:53 INFO  StreamThread:250 - stream-thread [word-count-b83c725f-2c5a-4176-a382-e67c3dee9b4a-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING
2024-08-05 13:36:53 INFO  KafkaStreams:346 - stream-client [word-count-b83c725f-2c5a-4176-a382-e67c3dee9b4a] State transition from REBALANCING to RUNNING
2024-08-05 13:36:53 INFO  LegacyKafkaConsumer:1047 - [Consumer clientId=word-count-b83c725f-2c5a-4176-a382-e67c3dee9b4a-StreamThread-1-consumer, groupId=word-count] Requesting the log end offset for word-count-KSTREAM-AGGREGATE-STATE-STORE-0000000004-repartition-0 in order to compute lag
